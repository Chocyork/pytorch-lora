{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffb4d31cc10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make torch deterministic\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# Exclude all instances corresponding to the digit 9\n",
    "exclude_indices = mnist_trainset.targets == 9\n",
    "mnist_trainset.data = mnist_trainset.data[~exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[~exclude_indices]\n",
    "\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set (don't exclude any digits)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create an overly expensive neural network to classify MNIST digits\n",
    "# Daddy got money, so I don't care about efficiency\n",
    "class RichBoyNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=1000, hidden_size_2=2000):\n",
    "        super(RichBoyNet,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_size_1) \n",
    "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n",
    "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, img): #convert + flatten\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "net = RichBoyNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5406/5406 [00:21<00:00, 257.17it/s, loss=0.208]\n",
      "Epoch 2: 100%|██████████| 5406/5406 [00:19<00:00, 270.85it/s, loss=0.115]\n",
      "Epoch 3: 100%|██████████| 5406/5406 [00:19<00:00, 275.18it/s, loss=0.0844]\n",
      "Epoch 4: 100%|██████████| 5406/5406 [00:19<00:00, 270.84it/s, loss=0.0769]\n",
      "Epoch 5: 100%|██████████| 5406/5406 [00:20<00:00, 268.73it/s, loss=0.0666]\n",
      "Epoch 6: 100%|██████████| 5406/5406 [00:19<00:00, 277.45it/s, loss=0.0641]\n",
      "Epoch 7: 100%|██████████| 5406/5406 [00:19<00:00, 275.22it/s, loss=0.0582]\n",
      "Epoch 8: 100%|██████████| 5406/5406 [00:20<00:00, 262.75it/s, loss=0.0549]\n",
      "Epoch 9: 100%|██████████| 5406/5406 [00:20<00:00, 264.58it/s, loss=0.0532]\n",
      "Epoch 10: 100%|██████████| 5406/5406 [00:19<00:00, 271.20it/s, loss=0.0483]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs=5):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x.view(-1, 28*28))\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "train(train_loader, net, epochs=10)\n",
    "\n",
    "original_weights = {}\n",
    "for name, param in net.named_parameters():\n",
    "    original_weights[name] = param.clone().detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 391.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.883\n",
      "wrong counts for 0: 8\n",
      "wrong counts for 1: 7\n",
      "wrong counts for 2: 30\n",
      "wrong counts for 3: 17\n",
      "wrong counts for 4: 18\n",
      "wrong counts for 5: 25\n",
      "wrong counts for 6: 17\n",
      "wrong counts for 7: 17\n",
      "wrong counts for 8: 23\n",
      "wrong counts for 9: 1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    wrong_counts = [0 for i in range(10)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = net(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                else:\n",
    "                    wrong_counts[y[idx]] +=1\n",
    "                total +=1\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')\n",
    "    for i in range(len(wrong_counts)):\n",
    "        print(f'wrong counts for {i}: {wrong_counts[i]}')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000])\n",
      "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000])\n",
      "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the weights matrices of the network\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    print(\n",
    "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRAParametrization(nn.Module):\n",
    "    def __init__(self, features_in, features_out, rank=4, lora_alpha=1, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
    "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        self.lora_alpha, self.rank = lora_alpha, rank\n",
    "        self.scale = lora_alpha / rank\n",
    "        self.enabled = True\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.enabled:\n",
    "            # Return X + (B*A)*scale\n",
    "            return X + torch.matmul(self.lora_B, self.lora_A).view(X.shape) * self.scale\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W: torch.Size([1000, 784]) + B: torch.Size([1000]) + Lora_A: torch.Size([4, 784]) + Lora_B: torch.Size([1000, 4])\n",
      "Layer 2: W: torch.Size([2000, 1000]) + B: torch.Size([2000]) + Lora_A: torch.Size([4, 1000]) + Lora_B: torch.Size([2000, 4])\n",
      "Layer 3: W: torch.Size([10, 2000]) + B: torch.Size([10]) + Lora_A: torch.Size([4, 2000]) + Lora_B: torch.Size([10, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.parametrize as parametrize\n",
    "\n",
    "\n",
    "def linear_layer_parameterization(layer, device, rank=4, lora_alpha=1):\n",
    "    features_in, features_out = layer.weight.shape\n",
    "    return LoRAParametrization(\n",
    "        features_in, features_out, rank=rank, lora_alpha=lora_alpha, device=device\n",
    "    )\n",
    "\n",
    "\n",
    "parametrize.register_parametrization(\n",
    "    net.linear1, \"weight\", linear_layer_parameterization(net.linear1, device)\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    net.linear2, \"weight\", linear_layer_parameterization(net.linear2, device)\n",
    ")\n",
    "parametrize.register_parametrization(\n",
    "    net.linear3, \"weight\", linear_layer_parameterization(net.linear3, device)\n",
    ")\n",
    "\n",
    "\n",
    "def enable_disable_lora(enabled=True):\n",
    "    for layer in [net.linear1, net.linear2, net.linear3]:\n",
    "        layer.parametrizations[\"weight\"][0].enabled = enabled\n",
    "\n",
    "for index, layer in enumerate([net.linear1, net.linear2, net.linear3]):\n",
    "    print(\n",
    "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing linear1.bias\n",
      "Freezing linear1.parametrizations.weight.original\n",
      "Freezing linear2.bias\n",
      "Freezing linear2.parametrizations.weight.original\n",
      "Freezing linear3.bias\n",
      "Freezing linear3.parametrizations.weight.original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/595 [00:00<?, ?it/s, loss=63.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 595/595 [00:02<00:00, 253.48it/s, loss=9.34]\n"
     ]
    }
   ],
   "source": [
    "# Freeze the non-Lora parameters\n",
    "for name, param in net.named_parameters():\n",
    "    if 'lora' not in name:\n",
    "        print(f'Freezing {name}')\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Load the MNIST dataset again, by keeping only the digit 9\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_trainset.data = mnist_trainset.data[exclude_indices]\n",
    "mnist_trainset.targets = mnist_trainset.targets[exclude_indices]\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Train the network with LoRA\n",
    "train(train_loader, net, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the frozen parameters are still unchanged by the finetuning\n",
    "assert torch.all(net.linear1.parametrizations.weight.original == original_weights['linear1.weight'])\n",
    "assert torch.all(net.linear2.parametrizations.weight.original == original_weights['linear2.weight'])\n",
    "assert torch.all(net.linear3.parametrizations.weight.original == original_weights['linear3.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 316.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.617\n",
      "wrong counts for 0: 185\n",
      "wrong counts for 1: 194\n",
      "wrong counts for 2: 281\n",
      "wrong counts for 3: 247\n",
      "wrong counts for 4: 759\n",
      "wrong counts for 5: 409\n",
      "wrong counts for 6: 54\n",
      "wrong counts for 7: 775\n",
      "wrong counts for 8: 927\n",
      "wrong counts for 9: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA enabled\n",
    "enable_disable_lora(enabled=True)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:02<00:00, 334.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.883\n",
      "wrong counts for 0: 8\n",
      "wrong counts for 1: 7\n",
      "wrong counts for 2: 30\n",
      "wrong counts for 3: 17\n",
      "wrong counts for 4: 18\n",
      "wrong counts for 5: 25\n",
      "wrong counts for 6: 17\n",
      "wrong counts for 7: 17\n",
      "wrong counts for 8: 23\n",
      "wrong counts for 9: 1009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with LoRA enabled\n",
    "enable_disable_lora(enabled=False)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get a batch of data\n",
    "# x, y = next(iter(test_loader))\n",
    "# x = x.to(device)\n",
    "# y = y.to(device)\n",
    "\n",
    "# plt.imshow(x[0].cpu().view(28, 28))\n",
    "# plt.show()\n",
    "# print(torch.argmax(net(x[0].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
